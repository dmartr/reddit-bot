{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import praw, re, collections, nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to create a \"bot\" that retrieves all the comments from a subreddit and creates a cool visualization of the trending words in them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getComments(subreddit, n):\n",
    "    c_list = []\n",
    "    r = praw.Reddit(user_agent='dummy-app')\n",
    "    subreddit = r.get_subreddit(subreddit)\n",
    "    top = subreddit.get_top(params={'t': 'all'}, limit=500)\n",
    "    all_comments = []\n",
    "    for submission in top: \n",
    "        submission_comments = praw.helpers.flatten_tree(submission.comments)\n",
    "        #don't include non comment objects such as \"morecomments\"\n",
    "        real_comments = [comment for comment in submission_comments if isinstance(comment, praw.objects.Comment)]\n",
    "        all_comments += real_comments\n",
    "    all_comments.sort(key=lambda comment: comment.score, reverse=True)\n",
    "    top_comments = all_comments[:n] #top n comments\n",
    "    for comment in top_comments:\n",
    "        c_list.append(str(comment))\n",
    "    return c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments = getComments('news', 50) #get top 10 comments from all the posts in /r/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commentsToWords(comments):\n",
    "    wordList = []\n",
    "    for comment in comments:\n",
    "        comment = re.sub(\"[^a-zA-Z]\",  \" \", comment) #get only letters\n",
    "        comment = comment.lower()\n",
    "        words = comment.split()\n",
    "        words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "        print(words)\n",
    "        wordList.append(words)\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmartr/anaconda/lib/python3.5/site-packages/nltk/corpus/reader/wordlist.py:25: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/dmartr/nltk_data/corpora/stopwords/english'>\n",
      "  return concat([self.open(f).read() for f in fileids])\n"
     ]
    }
   ],
   "source": [
    "words = commentsToWords(comments)\n",
    "print(len(commentsToWords(comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'old': 3, 'said': 3, 'called': 2, 'poor': 2, 'using': 2, 'dea': 2, 'would': 2, 'next': 2, 'anyone': 2, 'picture': 2, 'video': 2, 'five': 2, 'going': 2, 'two': 2, 'like': 2, 'father': 1, 'legitimate': 1, 'emergehand': 1, 'largely': 1, 'local': 1, 'com': 1, 'marijuana': 1, 'hoardedhttp': 1, 'agency': 1, 'applying': 1, 'corrupt': 1, 'concludes': 1, 'reasonhired': 1, 'scott': 1, 'passes': 1, 'million': 1, 'getkayaker': 1, 'cortes': 1, 'football': 1, 'qpobd': 1, 'prove': 1, 'right': 1, 'minnesota': 1, 'fact': 1, 'draw': 1, 'bullet': 1, 'muslims': 1, 'less': 1, 'useofficial': 1, 'facet': 1, 'car': 1, 'school': 1, 'logical': 1, 'raprove': 1, 'show': 1, 'medicinal': 1, 'reactor': 1, 'back': 1, 'ive': 1, 'hospital': 1, 'yocourse': 1, 'else': 1, 'firearms': 1, 'never': 1, 'coal': 1, 'ms': 1, 'chief': 1, 'companiesfolding': 1, 'sex': 1, 'shit': 1, 'water': 1, 'windepressing': 1, 'step': 1, 'super': 1, 'michael': 1, 'claims': 1, 'conflict': 1, 'plantscampaign': 1, 'must': 1, 'gay': 1, 'kudos': 1, 'walls': 1, 'wednesday': 1, 'need': 1, 'liable': 1, 'postbig': 1, 'deathlove': 1, 'vikingmeanwhile': 1, 'billionaire': 1, 'jack': 1, 'afford': 1, 'writers': 1, 'subway': 1, 'kids': 1, 'championships': 1, 'line': 1, 'penalty': 1, 'coss': 1, 'reminder': 1, 'burton': 1, 'many': 1, 'interest': 1, 'plantswrong': 1, 'hitting': 1, 'gawker': 1, 'flood': 1, 'imgur': 1, 'inefficient': 1, 'etcairliner': 1, 'editor': 1, 'gun': 1, 'sue': 1, 'juarez': 1, 'mediatsa': 1, 'jfk': 1, 'everyone': 1, 'pricelaw': 1, 'new': 1, 'gets': 1, 'gays': 1, 'fotruly': 1, 'courts': 1, 'something': 1, 'run': 1, 'deadly': 1, 'clear': 1, 'glad': 1, 'kris': 1, 'usgot': 1, 'sure': 1, 'enough': 1, 'signs': 1, 'pay': 1, 'clpluto': 1, 'found': 1, 'hogan': 1, 'held': 1, 'buck': 1, 'three': 1, 'seeimagine': 1, 'driver': 1, 'tell': 1, 'discovered': 1, 'worker': 1, 'important': 1, 'olympic': 1, 'sent': 1, 'lot': 1, 'flowing': 1, 'demolhell': 1, 'people': 1, 'taking': 1, 'giving': 1, 'solutgood': 1, 'actually': 1, 'stoned': 1, 'mentioned': 1, 'washington': 1, 'lookfun': 1, 'michelle': 1, 'fury': 1, 'victim': 1, 'boys': 1, 'choice': 1, 'incompetent': 1, 'injury': 1, 'construction': 1, 'cant': 1, 'fuck': 1, 'bingo': 1, 'actiontake': 1, 'tape': 1, 'hammremovedaustralia': 1, 'watough': 1, 'year': 1, 'comic': 1, 'house': 1, 'drunk': 1, 'read': 1, 'community': 1, 'lawoutrage': 1, 'lunch': 1, 'lost': 1, 'goes': 1, 'police': 1, 'hitman': 1, 'twist': 1, 'risks': 1, 'companiesfeel': 1, 'regular': 1, 'copyright': 1, 'years': 1, 'surgery': 1, 'decidingdeletedheard': 1, 'guytwo': 1, 'known': 1, 'prime': 1, 'article': 1, 'cruz': 1, 'began': 1, 'morning': 1, 'montgawker': 1, 'time': 1, 'home': 1, 'want': 1, 'matter': 1, 'bowl': 1, 'goiperkins': 1, 'weeks': 1, 'minutes': 1, 'season': 1, 'rallies': 1, 'familysomeone': 1, 'bring': 1, 'work': 1, 'delivery': 1, 'calling': 1, 'hitsofficer': 1, 'pastor': 1, 'fired': 1, 'daniels': 1, 'double': 1, 'ted': 1, 'netflix': 1, 'undiscussed': 1, 'start': 1, 'report': 1, 'recording': 1, 'get': 1, 'improvement': 1, 'thought': 1, 'comparing': 1, 'yanks': 1, 'insult': 1, 'murder': 1, 'nuclear': 1, 'tellingaustralians': 1, 'produces': 1, 'told': 1, 'common': 1, 'fyesterday': 1, 'internet': 1, 'war': 1, 'couch': 1, 'argument': 1, 'slamming': 1, 'taglinedeletedthink': 1, 'cityadding': 1, 'card': 1, 'sincwhite': 1, 'knife': 1, 'scornedknow': 1, 'phelps': 1, 'kid': 1, 'sagredo': 1, 'mornisenior': 1, 'ministers': 1, 'attempting': 1, 'gunshots': 1, 'hopefully': 1, 'hath': 1, 'finally': 1, 'manufacturers': 1, 'sense': 1, 'taxes': 1, 'punish': 1, 'hulk': 1, 'way': 1, 'radiation': 1, 'png': 1, 'roomtime': 1, 'god': 1, 'upon': 1, 'stuffed': 1, 'killed': 1, 'germansone': 1, 'sticks': 1, 'grandmaneed': 1, 'bill': 1, 'says': 1, 'stadium': 1, 'himsetime': 1})\n"
     ]
    }
   ],
   "source": [
    "wString = ''\n",
    "for w in words:\n",
    "    wString += \" \".join(w)\n",
    "bagsofwords = collections.Counter(re.findall(r'\\w+', wString))\n",
    "print(bagsofwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
